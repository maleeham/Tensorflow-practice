{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fashion_mnist = input_data.read_data_sets('data/fashion', source_url='http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/' , one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (images) shape: (55000, 784)\n",
      "Training set (labels) shape: (55000, 10)\n",
      "Test set (images) shape: (10000, 784)\n",
      "Test set (labels) shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Shapes of training set\n",
    "print(\"Training set (images) shape: {shape}\".format(shape=fashion_mnist.train.images.shape))\n",
    "print(\"Training set (labels) shape: {shape}\".format(shape=fashion_mnist.train.labels.shape))\n",
    "\n",
    "# Shapes of test set\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=fashion_mnist.test.images.shape))\n",
    "print(\"Test set (labels) shape: {shape}\".format(shape=fashion_mnist.test.labels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    " 0: \"T-shirt/top\",\n",
    " 1: \"Trouser\",\n",
    " 2: \"Pullover\",\n",
    " 3: \"Dress\",\n",
    " 4: \"Coat\",\n",
    " 5: \"Sandal\",\n",
    " 6: \"Shirt\",\n",
    " 7: \"Sneaker\",\n",
    " 8: \"Bag\",\n",
    " 9: \"Ankle boot\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 9 (Ankle boot)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbe48066630>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample 1\n",
    "\n",
    "# Get 28x28 image\n",
    "sample_1 = fashion_mnist.train.images[5].reshape(28,28)\n",
    "# Get corresponding integer label from one-hot encoded data\n",
    "sample_label_1 = np.where(fashion_mnist.train.labels[5] == 1)[0][0]\n",
    "# Plot sample\n",
    "print(\"y = {label_index} ({label})\".format(label_index=sample_label_1, label=label_dict[sample_label_1]))\n",
    "plt.imshow(sample_1, cmap='Greys')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_wgts(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(init_random_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    \"\"\"\n",
    "    x -> [batch, H, W, Channels]\n",
    "    W -> [filter H, Filter W, Channel IN, Channel OUT]\n",
    "    Use a stride of 1, keep padding same\n",
    "    \"\"\"\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2by2(x):\n",
    "    \"\"\"\n",
    "    x --> [batch, h, w, channels], a 4D Tensor\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1],\n",
    "                          strides=[1,2,2,1],\n",
    "                          padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x, shape):\n",
    "    W= init_wgts(shape)\n",
    "    b= init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_wgts([input_size,size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholders\n",
    "x= tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_true = tf.placeholder(tf.float32, shape = [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 1\n",
    "convo_1 = convolutional_layer(x_image, shape = [5,5,1,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)\n",
    "\n",
    "#layer 2\n",
    "convo_2= convolutional_layer(convo_1_pooling, shape= [2,2,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)\n",
    "\n",
    "#flatten it out\n",
    "convo_2_flat = tf.reshape(convo_2_pooling, [-1, 7*7*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat, 1064))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob = hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_pred label\n",
    "y_pred = normal_full_layer(full_one_dropout, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true, logits= y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "optimizer= tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step0\n",
      "Test Accuracy is:\n",
      "0.12\n",
      "\n",
      "\n",
      "Currently on step100\n",
      "Test Accuracy is:\n",
      "0.6446\n",
      "\n",
      "\n",
      "Currently on step200\n",
      "Test Accuracy is:\n",
      "0.7402\n",
      "\n",
      "\n",
      "Currently on step300\n",
      "Test Accuracy is:\n",
      "0.7754\n",
      "\n",
      "\n",
      "Currently on step400\n",
      "Test Accuracy is:\n",
      "0.7978\n",
      "\n",
      "\n",
      "Currently on step500\n",
      "Test Accuracy is:\n",
      "0.8168\n",
      "\n",
      "\n",
      "Currently on step600\n",
      "Test Accuracy is:\n",
      "0.8178\n",
      "\n",
      "\n",
      "Currently on step700\n",
      "Test Accuracy is:\n",
      "0.8334\n",
      "\n",
      "\n",
      "Currently on step800\n",
      "Test Accuracy is:\n",
      "0.8393\n",
      "\n",
      "\n",
      "Currently on step900\n",
      "Test Accuracy is:\n",
      "0.8347\n",
      "\n",
      "\n",
      "Currently on step1000\n",
      "Test Accuracy is:\n",
      "0.847\n",
      "\n",
      "\n",
      "Currently on step1100\n",
      "Test Accuracy is:\n",
      "0.8494\n",
      "\n",
      "\n",
      "Currently on step1200\n",
      "Test Accuracy is:\n",
      "0.8502\n",
      "\n",
      "\n",
      "Currently on step1300\n",
      "Test Accuracy is:\n",
      "0.8569\n",
      "\n",
      "\n",
      "Currently on step1400\n",
      "Test Accuracy is:\n",
      "0.8556\n",
      "\n",
      "\n",
      "Currently on step1500\n",
      "Test Accuracy is:\n",
      "0.8563\n",
      "\n",
      "\n",
      "Currently on step1600\n",
      "Test Accuracy is:\n",
      "0.8595\n",
      "\n",
      "\n",
      "Currently on step1700\n",
      "Test Accuracy is:\n",
      "0.8601\n",
      "\n",
      "\n",
      "Currently on step1800\n",
      "Test Accuracy is:\n",
      "0.8655\n",
      "\n",
      "\n",
      "Currently on step1900\n",
      "Test Accuracy is:\n",
      "0.8647\n",
      "\n",
      "\n",
      "Currently on step2000\n",
      "Test Accuracy is:\n",
      "0.8677\n",
      "\n",
      "\n",
      "Currently on step2100\n",
      "Test Accuracy is:\n",
      "0.8702\n",
      "\n",
      "\n",
      "Currently on step2200\n",
      "Test Accuracy is:\n",
      "0.8742\n",
      "\n",
      "\n",
      "Currently on step2300\n",
      "Test Accuracy is:\n",
      "0.8753\n",
      "\n",
      "\n",
      "Currently on step2400\n",
      "Test Accuracy is:\n",
      "0.8766\n",
      "\n",
      "\n",
      "Currently on step2500\n",
      "Test Accuracy is:\n",
      "0.8739\n",
      "\n",
      "\n",
      "Currently on step2600\n",
      "Test Accuracy is:\n",
      "0.8791\n",
      "\n",
      "\n",
      "Currently on step2700\n",
      "Test Accuracy is:\n",
      "0.8784\n",
      "\n",
      "\n",
      "Currently on step2800\n",
      "Test Accuracy is:\n",
      "0.8794\n",
      "\n",
      "\n",
      "Currently on step2900\n",
      "Test Accuracy is:\n",
      "0.8776\n",
      "\n",
      "\n",
      "Currently on step3000\n",
      "Test Accuracy is:\n",
      "0.8769\n",
      "\n",
      "\n",
      "Currently on step3100\n",
      "Test Accuracy is:\n",
      "0.8827\n",
      "\n",
      "\n",
      "Currently on step3200\n",
      "Test Accuracy is:\n",
      "0.8843\n",
      "\n",
      "\n",
      "Currently on step3300\n",
      "Test Accuracy is:\n",
      "0.8848\n",
      "\n",
      "\n",
      "Currently on step3400\n",
      "Test Accuracy is:\n",
      "0.8867\n",
      "\n",
      "\n",
      "Currently on step3500\n",
      "Test Accuracy is:\n",
      "0.8848\n",
      "\n",
      "\n",
      "Currently on step3600\n",
      "Test Accuracy is:\n",
      "0.886\n",
      "\n",
      "\n",
      "Currently on step3700\n",
      "Test Accuracy is:\n",
      "0.8847\n",
      "\n",
      "\n",
      "Currently on step3800\n",
      "Test Accuracy is:\n",
      "0.8878\n",
      "\n",
      "\n",
      "Currently on step3900\n",
      "Test Accuracy is:\n",
      "0.8869\n",
      "\n",
      "\n",
      "Currently on step4000\n",
      "Test Accuracy is:\n",
      "0.8852\n",
      "\n",
      "\n",
      "Currently on step4100\n",
      "Test Accuracy is:\n",
      "0.8873\n",
      "\n",
      "\n",
      "Currently on step4200\n",
      "Test Accuracy is:\n",
      "0.8888\n",
      "\n",
      "\n",
      "Currently on step4300\n",
      "Test Accuracy is:\n",
      "0.8872\n",
      "\n",
      "\n",
      "Currently on step4400\n",
      "Test Accuracy is:\n",
      "0.8946\n",
      "\n",
      "\n",
      "Currently on step4500\n",
      "Test Accuracy is:\n",
      "0.8921\n",
      "\n",
      "\n",
      "Currently on step4600\n",
      "Test Accuracy is:\n",
      "0.8886\n",
      "\n",
      "\n",
      "Currently on step4700\n",
      "Test Accuracy is:\n",
      "0.8949\n",
      "\n",
      "\n",
      "Currently on step4800\n",
      "Test Accuracy is:\n",
      "0.8884\n",
      "\n",
      "\n",
      "Currently on step4900\n",
      "Test Accuracy is:\n",
      "0.8927\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "\n",
    "with session as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        batch_x, batch_y = fashion_mnist.train.next_batch(500)\n",
    "        \n",
    "        #grab from the next batch\n",
    "        sess.run(train, feed_dict={x:batch_x, y_true:batch_y, hold_prob:0.7})\n",
    "       \n",
    "        #print out message every 100\n",
    "        if i%100 == 0:\n",
    "            print(\"Currently on step{}\".format(i))\n",
    "            print(\"Test Accuracy is:\")\n",
    "            #Test the train model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1), tf.argmax(y_true,1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "            print(sess.run(acc, feed_dict = {x:fashion_mnist.test.images, y_true:fashion_mnist.test.labels, hold_prob:0.5}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
