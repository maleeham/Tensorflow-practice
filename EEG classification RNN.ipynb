{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the random seed for reproducibility\n",
    "import random \n",
    "seed = 42\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all stuff\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg1 and events1 are the test data from a single person\n",
    "# code assumes eeg1 and events1 are csv files in the working dir\n",
    "eeg1 = pd.read_csv(\"input/datasets/onepanel/eeg-csv-dataset/1/eeg1.csv\", delimiter=\"\\t\")\n",
    "new_cols = eeg1.columns.values\n",
    "new_cols[0] = 'time'\n",
    "new_cols[33] = 'sample'\n",
    "eeg1.columns = new_cols\n",
    "\n",
    "events1 = pd.read_csv(\"input/datasets/onepanel/events1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample of data to ease building the model, unused in final run\n",
    "eeg1_smol = eeg1[0:785000]\n",
    "events_smol = events1[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data generator, unused in final run\n",
    "\n",
    "def generate_eeg(samples, time_steps, n_features, event_types):\n",
    "    # samples is Int number of trials \n",
    "    # time_steps is Int length of each trial in ms\n",
    "    # n_features is Int number of EEG channels\n",
    "    # event_types is Int number of stimula like lights and flashes\n",
    "    signals = generate_signals(samples, time_steps, n_features)\n",
    "    events = generate_events(event_types, samples)\n",
    "    events_1hot = one_hot_events(events)\n",
    "    return signals, events_1hot\n",
    "\n",
    "# helper function (generate_eeg) for making EEG signal data\n",
    "def generate_signals(samples, time_steps, n_features):\n",
    "    # data types same as main function\n",
    "    signals = np.random.random((samples, time_steps, n_features))\n",
    "    return signals\n",
    "\n",
    "# helper function (generate_eeg) for making one sample per event an\n",
    "def generate_events(event_types, samples):\n",
    "    # data types same as main function\n",
    "    events = np.random.randint(1, event_types, samples)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in eeg dataframe and event dataframe, cleans them, \n",
    "# 1hot encodes the events\n",
    "def clean_eeg(eeg, events, event_interval_length, eeg_slice_length):\n",
    "    #event_list = []\n",
    "    array_list = [] \n",
    "    index_list = []\n",
    "    eeg = standardize_eeg(eeg)\n",
    "    \"\"\"\n",
    "    function for standardizing the eeg readings\n",
    "    events_new = build_zero_events(events)\n",
    "    iterate over the rows of the events and slice out the corresponding eeg data\n",
    "    \"\"\"\n",
    "    for index, row in itertools.islice(events.iterrows(), event_interval_length): \n",
    "        # loop through events data\n",
    "        #build_event_list(row, event_list) #\n",
    "        tmin, tmax = build_event_intervals(row, events)\n",
    "        eeg_slice = cut_event_intervals(eeg, tmin, tmax)\n",
    "        array_list, index_list = build_array(eeg_slice, eeg_slice_length, \n",
    "                                             index, index_list, array_list)\n",
    "    y_int = events.iloc[index_list] # take the event types for the correct index\n",
    "    y_int = y_int['type'].values    # take just the event types as an array\n",
    "    #y_int = y_int.as_matrix()            # save the event types as a matrix\n",
    "    #y, lb = one_hot_events(y_int)        # one-hot the event types and save the binarizer\n",
    "    X = np.stack(array_list, axis = 0)   # stack the arrays so the whole thing is 3D\n",
    "    return X, y_int                     # return the data, outputs, and the binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_event_list(row, event_list):\n",
    "    # helper function to pull event types out of event data in the right order\n",
    "    event_type = getattr(row, \"type\")\n",
    "    event_list.append(event_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_event_intervals(row, events):\n",
    "    # helper function to get the time intervals associated with each event\n",
    "    tmin = getattr(row, \"latency\")\n",
    "    tmin_in = getattr(row, \"number\")\n",
    "    tmax_in = tmin_in + 1\n",
    "    tmax = events1.loc[tmax_in, \"latency\"]\n",
    "    return tmin, tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_event_intervals(eeg, tmin, tmax):\n",
    "    # helper function to slice up the eeg data so each slice is associated with one event\n",
    "    eeg_slice = eeg.loc[(eeg[\"time\"] > tmin) & (eeg[\"time\"] < tmax)]\n",
    "    eeg_slice.drop([\"time\", \"sample\"], axis = 1, inplace = True)\n",
    "    return eeg_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_array(eeg_slice, eeg_slice_length, index, index_list, array_list):\n",
    "    # helper function to build an array out of the eeg slices and pad them out to a standard length\n",
    "    if len(eeg_slice) < eeg_slice_length:\n",
    "        index_list.append(index)\n",
    "        eeg_matrix = eeg_slice.as_matrix()\n",
    "        padded_matrix = np.pad(eeg_matrix, ((0, eeg_slice_length - len(eeg_matrix)), (0,0)),\n",
    "                                   'constant', constant_values=0)\n",
    "        array_list.append(padded_matrix)\n",
    "    return array_list, index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_events(events):\n",
    "    # helper function for one-hot encoding the events\n",
    "    events_list = list(events)\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(events_list)\n",
    "    events_1hot = lb.transform(events_list)\n",
    "    return events_1hot, lb\n",
    "\n",
    "def invert_one_hot(events, lb):\n",
    "    # function for decoding one-hot, binarizer made in one_hot_events\n",
    "    inv_events = lb.inverse_transform(events)\n",
    "    return inv_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_eeg(eeg_data):\n",
    "    # breaks apart an eeg dataframe, scales the eeg readings, and reassmbles it into a dataframe\n",
    "    column_list = eeg_data.columns[1:33]\n",
    "    time = eeg_data['time']\n",
    "    sample = eeg_data['sample']\n",
    "    eeg_array = eeg_data[column_list]\n",
    "    eeg_stnd = scale_data(eeg_array)\n",
    "    eeg_stnd_df = pd.DataFrame(eeg_stnd, index=eeg_data.index, columns=column_list)\n",
    "    eeg_stnd = pd.concat([time, eeg_stnd_df, sample], axis =1)\n",
    "    return eeg_stnd\n",
    "\n",
    "def scale_data(unscaled_data):\n",
    "    # helper function for standardize_eeg, fits a scaler and transforms the data \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(unscaled_data)\n",
    "    scaled_data = scaler.transform(unscaled_data)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is unused code for breaking up the \"nothing happened\" periods of the eeg data \n",
    "# to associate with \"type 0\" events. \n",
    "\n",
    "import math\n",
    "time_steps = 1300\n",
    "\n",
    "def build_zero_events(event_data, time_steps=time_steps):\n",
    "    new_events = build_new_events(event_data, time_steps)\n",
    "    events = zero_events(event_data, new_events)\n",
    "    return events\n",
    "\n",
    "\n",
    "def build_new_events(event_data, time_steps= time_steps):\n",
    "    first_event_time = event_data['latency'].loc[1]\n",
    "    number_new_intervals = math.floor(first_event_time / time_steps)\n",
    "    df = pd.DataFrame(columns=['number', 'latency', 'type', 'duration'],index = range(number_new_intervals) )\n",
    "    latency = 0\n",
    "    for t in range(number_new_intervals):\n",
    "        latency += 1300\n",
    "        df.loc[t].latency = latency\n",
    "        df.loc[t].type = 0\n",
    "    return df\n",
    "\n",
    "def zero_events(event_data, new_events):\n",
    "    events_zeros = event_data[event_data.latency != 1]\n",
    "    events_zeros= new_events.append(events_zeros)\n",
    "    events_zeros = events_zeros.reset_index(drop=True)\n",
    "    events_zeros['number'] = events_zeros.index + 1\n",
    "    return events_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples    = 3625\n",
    "n_features = 32\n",
    "time_steps = 1300\n",
    "event_types= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onepanel/.conda/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/home/onepanel/.conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# get the data into useable form and store as X and y\n",
    "X, y = clean_eeg(eeg1, events1, samples, time_steps)  #4250 long, 998 short, 4330 long enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes the minor event types. There were only a couple hundred examples of each, whereas the used events had a \n",
    "# couple thousand examples\n",
    "remove_list = [0,2,4,5,6]              # designate unwanted event types\n",
    "drop_list = np.isin(y, remove_list)    # create a list of indices associated with unwanted events                  \n",
    "drop_array = np.array(drop_list)       # make the list of indices to drop into an array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make X, y's with unwanted events removed\n",
    "y_short_int = y[np.isin(y, remove_list, invert=True)]\n",
    "X_short     = X[np.isin(y, remove_list, invert=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the y data without the unwanted events\n",
    "y_short, lb = one_hot_events(y_short_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# use strat.shuffle.split to get indices for test and training data\n",
    "sss = StratifiedShuffleSplit(n_splits = 2, test_size = 0.2, random_state = seed)\n",
    "sss.get_n_splits(X_short, y_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the indices generated by stratified shuffle split and make the test and training datasets\n",
    "for train_index, test_index in sss.split(X_short, y_short):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_short[train_index], X_short[test_index]\n",
    "    y_train, y_test = y_short[train_index], y_short[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2444/2444 [==============================] - 162s 66ms/step - loss: 0.6817 - acc: 0.5966\n",
      "Epoch 2/50\n",
      "2444/2444 [==============================] - 164s 67ms/step - loss: 0.6758 - acc: 0.5978\n",
      "Epoch 3/50\n",
      "2444/2444 [==============================] - 162s 66ms/step - loss: 0.6745 - acc: 0.5990\n",
      "Epoch 4/50\n",
      "1152/2444 [=============>................] - ETA: 1:24 - loss: 0.6763 - acc: 0.5981"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(LSTM(100, return_sequences = False, input_shape= (time_steps, n_features)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss= 'binary_crossentropy',\n",
    "              optimizer = 'rmsprop',\n",
    "              metrics   = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs =50)\n",
    "score= model.evaluate(X_test, y_test, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score\n",
    "print(\"Accuracy: %.2f%%\" % (score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
